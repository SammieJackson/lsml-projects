# Gradient Boosting 

Необходимо реализовать утилиту, позволяющую обучать градиентный бустинг на решающих деревьях быстро и качественно, а так же применять обученные модели. 

### Интерфейс

Утилита должна иметь два режима - обучение и применение. Работать она должна со стандартными файлами csv. При обучении она должна принимать путь к файлу с данными, количество деревьев и learning rate в качестве параметров и возвращать обученную модель.  В процессе обучения она должна логировать лосс после обучения каждого дерева. В режиме приминения она должна применять ранее обученную модель к тестовым данным и возвращать файл с предсказаниями.

### Принцип работы

Хочется сделать акцент на скорость работы, и быть, по крайней мере, не медленнее чем библиотека lightgbm. Для этого, проще всего, бустинг реализовывать на oblivious decision trees (если не знаете что это - в [этой](https://arxiv.org/pdf/1609.05610.pdf) статье есть рассказ о них). Не нужно придумывать механизм для оптимизации разных типов лоссов, пусть ваш бустинг минимизирует только [MSE](Mean squared error). 

Внутри предлагается реализовать популярный [histogram-based подход](https://github.com/Microsoft/LightGBM/blob/master/docs/Features.rst).

### Процесс сдачи задания:

0) Проект расчитан на 2-4 человек.

1) Реализуйте бибилиотеку, так как написанно выше. Сделать это надо на любом *компилируемом* языке. Позаботтесь о качестве кода. 

2) Библиотеку разместите на github.  Напишите к ней приятный ридми, в котором будет общее описание библиотеки и инструкция о том как её запустить и использовать.

3) Сравните свою библиотеку с популярными аналогами — *xgboost* и *lightgbm*. Оцените скорость работы и качество полученной модели на датасетах [Higgs](https://www.kaggle.com/c/higgs-boson/data) и [BCI](https://www.kaggle.com/c/inria-bci-challenge#evaluation). Опираться в бенчмарках можете на [этот](https://blogs.technet.microsoft.com/machinelearning/2017/07/25/lessons-learned-benchmarking-fast-machine-learning-algorithms/) пост. О результатах бенчмарков так же напишите в ридми вашего репозитория.

4) Мы почитаем ваш репозиторий и поставим вам оценку. Оцениваться будет качество результата, удобство и простота использования, а так же качество кода.

