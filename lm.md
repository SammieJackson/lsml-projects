# Scalable Linear Models

В этом проекте необходимо реализовать систему для обучения линейный моделей -- быстро работающую и поддерживающую, как минимум, такие наборы букв :  sgd, ftrl-proximal, adagrad. Утилита должна уметь сохранять обученную модель в удобном формате, и уметь применять её. Классификацию и регрессию нужно поддержать в виде отдельных режимов.

### Интерфейс

Утилита должна иметь два режима - обучение и применение. Работать нужно со стандартными файлами csv. При обучении она должна принимать, как минимум, путь к файлу с данными, тип обучаемого алгоритма, максимальный допустимый размер модели и темп обучения. 

### Принцип работы

Хочется, чтобы утилита была быстра и качественна. Постарайтесь применить все описанные на лекциях и семинарах трюки, хешируйте Фили, следите за эффективностью работы с памятью. Постарайтесь быть не медленнее чем vowpal wabbit.

### Процесс сдачи задания:

0) Проект расчитан на 1-3 человек.

1) Реализуйте бибилиотеку, так как написанно выше. Сделать это надо на любом *компилируемом* языке, позаботившись о качестве кода. 

2) Библиотеку разместите на github.  Напишите к ней приятный ридми, в котором будет общее описание библиотеки и инструкция о том как её запустить и использовать.

3) Сравните свою библиотеку с популярными аналогами — *vowpal wabbit* и *liblinear*. Оцените скорость работы и качество полученной модели на датасетах [Criteo](http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/) и [avazu](https://www.kaggle.com/c/avazu-ctr-prediction). Опираться в бенчмарках можете на [этот](https://blogs.technet.microsoft.com/machinelearning/2017/07/25/lessons-learned-benchmarking-fast-machine-learning-algorithms/) пост. О результатах бенчмарков так же напишите в ридми вашего репозитория.

4) Мы почитаем ваш репозиторий и поставим вам оценку. Оцениваться будет качество результата, удобство и простота использования, скорость, а так же качество кода.

